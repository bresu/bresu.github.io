<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Leander&#39;s Blog</title>
    <link>https://bresu.github.io/en/</link>
    <description>Leander&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>de-de</language>
    <lastBuildDate>Wed, 10 Jun 2020 00:00:00 +0000</lastBuildDate>
    
    <atom:link href="https://bresu.github.io/en/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>scraping austria - a painful lesson in webscraping</title>
      <link>https://bresu.github.io/en/posts/scraping_austria/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bresu.github.io/en/posts/scraping_austria/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://bresu.github.io/pics/scraping_austria/headerImage.png&#34; alt=&#34;√ñsterreichische Stadt am See&#34;&gt;
Servus! I got the inspiration for this project by a youtube video I watched. In the video, the guy scrapes some embassy websites and automatically sends an e-mail to every single embassy. It&amp;rsquo;s a very entertaining video, you can watch the &lt;a href=&#34;https://www.youtube.com/watch?v=Jbix9y8iV38&amp;amp;t=115s&#34;&gt;video here&lt;/a&gt;. Inspired by the &amp;ldquo;simple&amp;rdquo; approach, I thought: Well, embassies are taken, what else is there to scrape? And I wanted something more challenging than scraping 10 accumulating websites that have basically done my job already.
So I came up with something original:&lt;/p&gt;
&lt;h1 id=&#34;scraping-every-single-website-of-every-municipality-in-austria-&#34;&gt;scraping every single website of every municipality in austria üá¶üáπ
&lt;span&gt;&lt;a href=&#34;#scraping-every-single-website-of-every-municipality-in-austria-&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;The task was determined, now all I needed was a well thought out plan:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;find a list of ALL municipalities&lt;/li&gt;
&lt;li&gt;combine each municipality&amp;rsquo;s name with different domains&lt;/li&gt;
&lt;li&gt;find existing domains&lt;/li&gt;
&lt;li&gt;look for indicators that the current site is the correct one (and not just a registered, unused one or - even worse - a business site)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;Let&amp;rsquo;s go!&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&#34;finding-a-list---all-hail-statistik-austria&#34;&gt;finding a list - all hail statistik austria
&lt;span&gt;&lt;a href=&#34;#finding-a-list---all-hail-statistik-austria&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;Finding a complete and up-to-date list wasn&amp;rsquo;t quite as hard as I thought it would be. Turns out that Statistik Austria has some pretty cool stuff on their website, like &lt;a href=&#34;http://www.statistik.at/verzeichnis/reglisten/gemliste_knz.xls&#34;&gt;this table&lt;/a&gt; which contains every municipality, it&amp;rsquo;s postal code (PLZ) and it&amp;rsquo;s &lt;strong&gt;Gemeindekennziffer&lt;/strong&gt; (GKZ).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;What the hell is a GKZ?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://bresu.github.io/pics/scraping_austria/confusedDoggo.webp&#34; alt=&#34;Confused Dog&#34;&gt;&lt;/p&gt;
&lt;p&gt;Glad you asked! It&amp;rsquo;s a unique number assigned to each municipality, much like a postal code number, but still very much different. The GKZ has five digits, while the PLZ has only four. PLZs are an old system which has it&amp;rsquo;s pros and cons, the biggest disadvantage being that PLZs don&amp;rsquo;t have geographical meaningfulness:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2384 is the PLZ for Breitenfurt, Lower Austria&lt;/li&gt;
&lt;li&gt;3012 is the PLZ for Wolfsgraben, Lower Austria (only 4km away from the former)&lt;/li&gt;
&lt;li&gt;Vorarlberg&amp;rsquo;s PLZs all start with 6, which is also Tyrol&amp;rsquo;s first number&lt;/li&gt;
&lt;li&gt;Except South Tyrol&amp;rsquo;s PLZ: starts with 9, which is otherwise Carinthia&amp;rsquo;s!&lt;br&gt;
&lt;br&gt;
One can see: This system is not good, especially if you want to retrieve geographical data from it.&lt;br&gt;
That&amp;rsquo;s why Statistik Austria came up with the GKZ&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;the-genius-way-of-gkz&#34;&gt;the genius way of GKZ
&lt;span&gt;&lt;a href=&#34;#the-genius-way-of-gkz&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;As mentioned above the GKZ consists of 5 numbers:
The first representing the state with numbers 1 to 9.
Second and third represent the political districts within the state.
The last two digits represent the municipalities within that district.
So Bisamberg for example has the GKZ: 3 12 01&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;3: Lower Austria&lt;/li&gt;
&lt;li&gt;12: District of Korneuburg&lt;/li&gt;
&lt;li&gt;01: Bisamberg&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;
&lt;br&gt;&lt;br&gt;
&lt;em&gt;Way better!&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;combinations-and-permutations-are-a-pain-in-the-ass&#34;&gt;combinations and permutations are a pain in the ass
&lt;span&gt;&lt;a href=&#34;#combinations-and-permutations-are-a-pain-in-the-ass&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;So Austria has roughly 2100 municipalities. That&amp;rsquo;s a lot. Especially if you think about all possible combinations for domains.
&amp;lsquo;&amp;lsquo;&amp;lsquo;python
gemeinde_name = &amp;ldquo;Bisamberg&amp;rdquo;.lower()&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;list_possible_domains = [

    # If the website isn&#39;t in HTTPS, trying to access it via HTTPS will throw an error
    &amp;quot;http://www.{gemeinde_name}.gv.at&amp;quot;.format(gemeinde_name)

    # Not everybody uses .gv domains
    &amp;quot;http://www.{gemeinde_name}.at&amp;quot;.format(gemeinde_name)

    # Turns out: states have domains??? Mostly Tyrol (.tirol), Burgenland (.bgld) and Upper Austria (.ooe)
    &amp;quot;http://www.{gemeinde_name}.bgld.gv.at&amp;quot;.format(gemeinde_name)

]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&#39;&amp;rsquo;&amp;rsquo;
For one-worded municipalities this approach works fine but it won&amp;rsquo;t work with such as &amp;ldquo;Krems an der Donau&amp;rdquo;. Another example are all municipalities with &amp;ldquo;Sankt&amp;rdquo;, like &amp;ldquo;St. Georgen im Lavanttal&amp;rdquo;. The work-around I came up with is a very simple one:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ugly_gemeinde_name_1 = &amp;quot;Krems an der Donau&amp;quot;.lower()

split_gemeinde_name_1 = ugly_gemeinde_name_1.split(&amp;quot; &amp;quot;) // =&amp;gt; [&#39;krems&#39;,&#39;an&#39;,&#39;der&#39;,&#39;donau&#39;]

# Then I wrote some very ugly functions that format different possible domain names - I will spare you the details.
# In the end, the list of possible domains looked like this

list_of_possible_domains = [

    &amp;quot;http://www.krems.at&amp;quot;,
    &amp;quot;http://www.krems-an-der-donau.at&amp;quot;,
    &amp;quot;http://www.krems-donau.at&amp;quot;,
    &amp;quot;http://www.krems.gv.at&amp;quot;,
    &amp;quot;http://www.krems-an-der-donau.gv.at&amp;quot;,
    &amp;quot;http://www.krems-donau.gv.at&amp;quot;

# ... and more ]
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;requests-and-false-positives&#34;&gt;requests and false positives
&lt;span&gt;&lt;a href=&#34;#requests-and-false-positives&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;So after generating all possibilities, I cycled through them and sent a GET request to each one. If the domain doesn&amp;rsquo;t exist, python will throw an error and with a simple try except magic, you can easily catch those and verify existing sites.&lt;/p&gt;
&lt;h1 id=&#34;are-you-4-real&#34;&gt;are you 4 real?
&lt;span&gt;&lt;a href=&#34;#are-you-4-real&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;So it turned out: just because the site exists doesn&amp;rsquo;t mean that it&amp;rsquo;s the right one. There are business or private sites that use one of the generated domains. I had to check for keywords like &amp;ldquo;Rathaus&amp;rdquo;, &amp;ldquo;Gemeindeamt&amp;rdquo; etc. And even with these checks, I am pretty sure that there are STILL wrong sites in my table - nobody&amp;rsquo;s perfect!&lt;/p&gt;
&lt;h1 id=&#34;you-got-mail&#34;&gt;you got mail
&lt;span&gt;&lt;a href=&#34;#you-got-mail&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;After hours of crawling &amp;amp; scraping I finally had a table to work with for scraping the e-mail adresses. It&amp;rsquo;s basically the same step as before when I checked for keywords, only that this time I was looking for words like &amp;ldquo;Kontakt&amp;rdquo; and &amp;ldquo;Impressum&amp;rdquo; and then had to parse only the adress without any unwanted text like the &amp;ldquo;to:&amp;rdquo; junk. For this step I had to use selenium because many of the sites use an excessive amount of javascript. So I had to render it. But I actually really enjoyed working with selenium - very powerful tool!&lt;/p&gt;
&lt;p&gt;Now all that was left to do was to look for errors (there were a LOT) and some general cleanup and encoding issues. I learned a lot while doing this and also had a lot of fun. You can find the data on my &lt;a href=&#34;https://github.com/bresu/oe_gemeinden&#34;&gt;github&lt;/a&gt;.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;My &lt;a href=&#34;https://www.youtube.com/watch?v=77gKSp8WoRg&#34;&gt;hometown&lt;/a&gt;!&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>schools and privacy: don&#39;t mix!</title>
      <link>https://bresu.github.io/en/posts/webuntis/</link>
      <pubDate>Fri, 10 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bresu.github.io/en/posts/webuntis/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://bresu.github.io/pics/webuntis/stundenplan.jpg&#34; alt=&#34;StundenplanFoto&#34; title=&#34;Timetable&#34;&gt;&lt;/p&gt;
&lt;p&gt;If you are/ were a student in Austria during thr last 10 years, you probably came into contact with the company WebUntis. Mostly known for their timetable manager tool and security flaws.&lt;/p&gt;
&lt;p&gt;So the company&amp;rsquo;s reputation really isn&amp;rsquo;t the best when it comes to security vulnerabilities and how they handle them. It took them allegedly 5 months to close a XSS-vulnerability on their site&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; But for an austrian enterprise whose headquarters are located in Lower Austria they are actually doing pretty good.&lt;/p&gt;
&lt;p&gt;Or so I thought.&lt;/p&gt;
&lt;h1 id=&#34;school-admins-are-just-people-too&#34;&gt;School-Admins are just people too
&lt;span&gt;&lt;a href=&#34;#school-admins-are-just-people-too&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;Being responsible for the IT-System of a school must be horrible. Colleagues forget their passwords, the student-database needs to be constantly kept up-to-date and you have to work with horrible Software, such as &lt;strong&gt;Excel&lt;/strong&gt;(üòî), &lt;strong&gt;Word&lt;/strong&gt;(ü§Æ)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Heartfelt condolences to you, admins ‚ù§Ô∏è&lt;/p&gt;
&lt;p&gt;But nevertheless: some mistakes can not be forgiven!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So it turns out that most school administrators either did not read the WebUntis-Manuals carefully enough or they simply misunderstood the meaning of some website-settings. But these &amp;ldquo;minor&amp;rdquo; mistakes are the reason for why the data of 100s of students is freely accessible online.&lt;/p&gt;
&lt;h1 id=&#34;so-whats-the-problem-now&#34;&gt;So what&amp;rsquo;s the problem now?
&lt;span&gt;&lt;a href=&#34;#so-whats-the-problem-now&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;As much as I would like to show you what I mean by that: I won&amp;rsquo;t.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Why?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Because we are talking about data of minors, children. And this is not a &amp;ldquo;how-to-get-arrested tutorial&amp;rdquo;.
AFAIK 3 schools in and outside of Vienna are affected - roughly 1800 students total. The data you can access freely include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Class-Name ü§®&lt;/li&gt;
&lt;li&gt;First and Last name ü§®ü§®&lt;/li&gt;
&lt;li&gt;Electives and schedule ü§®ü§®&lt;/li&gt;
&lt;li&gt;Religious belief (can be deducted from religion-class) ü§®ü§®ü§®&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But what I can show you is how stupid some of WebUntis&#39; design really is!&lt;/p&gt;
&lt;p&gt;Enjoy üòÅ&lt;/p&gt;
&lt;h1 id=&#34;webuntis-security-bullshit&#34;&gt;WebUntis &lt;del&gt;Security&lt;/del&gt; &lt;em&gt;Bullshit&lt;/em&gt;
&lt;span&gt;&lt;a href=&#34;#webuntis-security-bullshit&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;When I went to school, our admin configured the timetable-accessibilty by groups. So if you were a student, you could see any other students timetable.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For a long time, I thought only our admin did this bad practice&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Turns out: &lt;em&gt;This is pretty normal for most schools!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This alone is a big security hazard. It only takes one students compromised account to get access to the whole network.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;But it even get&amp;rsquo;s better!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The default username and password can be configured and most of the time the login credentials look like this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Sch√ºler: Maximilian Mustermann (10.10.2001)&lt;/span&gt;
    Username: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;must.max&amp;#34;&lt;/span&gt;
    Password: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;20011010&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Every admin has the possibility to customize these defaults, so every school does their own thing - which is good for security!&lt;/p&gt;
&lt;p&gt;But oh boy you gotta look at this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://bresu.github.io/pics/webuntis/webuntisTutorial.jpg&#34; alt=&#34;Oh no&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üòê&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Apparently, a lot of schools send out guides on how to use WebUntis. With a little bit of Google-Dorking&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; you will find most of them. Now you know the default credential sytle üéâ And I am pretty sure that there will be some students that &lt;em&gt;don&amp;rsquo;t&lt;/em&gt; change their default password.&lt;/p&gt;
&lt;p&gt;But this alone is not yet the real problem!&lt;/p&gt;
&lt;p&gt;Once you are logged in, you can see your fellow students usernames. No fullnames?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Great, so where do the fullnames come from then?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Well, you can not only see everyones timetable, but you can also &lt;em&gt;print&lt;/em&gt; them:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://bresu.github.io/pics/webuntis/webuntisPlease.gif&#34; alt=&#34;I MADE THIS GIF WOOOO&#34;&gt;&lt;/p&gt;
&lt;p&gt;Clicking on that will open a new &lt;em&gt;window&lt;/em&gt; with the timetable being formatted in HTML (no PDFs are created)&lt;/p&gt;
&lt;p&gt;and what is that?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://bresu.github.io/pics/webuntis/webuntisFullname.jpg&#34; alt=&#34;Oh no, our timetable - it&amp;rsquo;s broken!&#34;&gt;&lt;/p&gt;
&lt;p&gt;Stay safe y&amp;rsquo;all&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://packetstormsecurity.com/files/157998/WebUntis-2020.12.1-Cross-Site-Scripting.html&#34;&gt;Bug report&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;also called &lt;a href=&#34;https://en.wikipedia.org/wiki/Google_hacking&#34;&gt;Google-Hacking&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>how to get a nearly anonymous sim-card (in austria)</title>
      <link>https://bresu.github.io/en/posts/2021-01-12-simsssss/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bresu.github.io/en/posts/2021-01-12-simsssss/</guid>
      <description>&lt;h1 id=&#34;how-to-get-a-nearly-anonymous-sim-card-in-austria&#34;&gt;how to get a nearly anonymous sim-card (in austria)
&lt;span&gt;&lt;a href=&#34;#how-to-get-a-nearly-anonymous-sim-card-in-austria&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;created: 1.12.2021&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;disclaimer&lt;/strong&gt;
&lt;em&gt;I do not advertise nor recommend using any method I mention in this post. I have never used and do not intend to use any method or concept described here.
These are just hypothetical and purely based on my imagination.&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&#34;lets-get-into-it&#34;&gt;let&amp;rsquo;s get into it
&lt;span&gt;&lt;a href=&#34;#lets-get-into-it&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;A spectre is haunting europe, the spectre of mandatory sim-card registration. Against popular belief, this is not the work of our friends in Belgium, but rather every european state
shares the same paranoia and compulsory urge to surveil their citizens even more. Even better: The EU came to the &lt;a href=&#34;https://netzpolitik.org/2013/vorratsdatenspeicherung-eu-kommission-legt-beweise-fuer-notwendigkeit-vor-beweist-aber-die-notwendigkeit-nicht/&#34;&gt;conclusion&lt;/a&gt; that sim-card registrations do &lt;strong&gt;not&lt;/strong&gt; help with combating crime, terrorism or other illegal activities. But the member states obviously don&amp;rsquo;t care.&lt;/p&gt;
&lt;h1 id=&#34;so-how-do-we-work-around-this-bullshit&#34;&gt;so, how do we work around this bullshit?
&lt;span&gt;&lt;a href=&#34;#so-how-do-we-work-around-this-bullshit&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;The first thing that comes to mind is &lt;em&gt;buying a card in one of the remaining member states, that do not require ID&lt;/em&gt;. So far so good.
Question is: which states are not affected yet?
Only few remain. E.g Serbia, Croatia and probably some other balkan states.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>influencing online polls like a pro</title>
      <link>https://bresu.github.io/en/posts/2020-11-16-pingpoll/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bresu.github.io/en/posts/2020-11-16-pingpoll/</guid>
      <description>&lt;p&gt;[under construction]&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>jugendwort des jahres 2021 ;)</title>
      <link>https://bresu.github.io/en/posts/2021-08-20-jugendwort_des_jahres_2021/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bresu.github.io/en/posts/2021-08-20-jugendwort_des_jahres_2021/</guid>
      <description>&lt;p&gt;[under construction]&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>nobody&#39;s perfect: a list of failed projects</title>
      <link>https://bresu.github.io/en/posts/2020-06-09-failures/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bresu.github.io/en/posts/2020-06-09-failures/</guid>
      <description>&lt;h1 id=&#34;this-is-gonna-be-a-long-site&#34;&gt;this is gonna be a long site
&lt;span&gt;&lt;a href=&#34;#this-is-gonna-be-a-long-site&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;created: 24.08.2021&lt;/p&gt;
&lt;h1 id=&#34;failure-plays-a-crucial-part-in-the-learning-process&#34;&gt;failure plays a crucial part in the learning process
&lt;span&gt;&lt;a href=&#34;#failure-plays-a-crucial-part-in-the-learning-process&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;So in order to learn a lot you also have to &lt;strong&gt;fail&lt;/strong&gt; a lot. But I also think that not every failure is equally good/ bad. Some of my projects failed because of time-related parameters for example &lt;em&gt;deadlines&lt;/em&gt;. Others failed because at the time when I was approaching the project I simply lacked the knowledge to realize my ideas.
And then there are projects that failed because I underestimated the amount of effort and/or resources it would take to realize them. Obviously some of these categories overlap, because if I had more knowledge I would have made progress quicker and the time-limits would not have been a problem.&lt;/p&gt;
&lt;h1 id=&#34;so---lets-begin&#34;&gt;So - Let&amp;rsquo;s begin!
&lt;span&gt;&lt;a href=&#34;#so---lets-begin&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;h1 id=&#34;victims-of-time&#34;&gt;victims of time
&lt;span&gt;&lt;a href=&#34;#victims-of-time&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;&lt;em&gt;learning mapbox&lt;/em&gt;
I only had a 1-month free trial and I didn&amp;rsquo;t know any javascript at the time&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(not yet a victim but soon to be: jugendwort des jahres 2021&lt;/em&gt;
I simply do not have the time and resources right now to do that&lt;/p&gt;
&lt;p&gt;&lt;em&gt;pausebot&lt;/em&gt;
I learned a lot and it was fun, but it was only trend that faded away&lt;/p&gt;
&lt;h1 id=&#34;victims-of-lacking-knowledge&#34;&gt;victims of lacking knowledge
&lt;span&gt;&lt;a href=&#34;#victims-of-lacking-knowledge&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;&lt;em&gt;further whatsapp analysis&lt;/em&gt;
I need to know more data science techniques to realize that  !&lt;/p&gt;
&lt;p&gt;&lt;em&gt;scraping pdf tables&lt;/em&gt;
It&amp;rsquo;s just fucking hard, definitely not impossible&lt;/p&gt;
&lt;p&gt;&lt;em&gt;don&amp;rsquo;t ask: mc donalds menu anaylsis&lt;/em&gt;
My idea was to scrape all nutritional info about mcdo&amp;rsquo;s products and then do cool functions on it.&lt;/p&gt;
&lt;h1 id=&#34;victims-of-being-naive&#34;&gt;victims of being naive
&lt;span&gt;&lt;a href=&#34;#victims-of-being-naive&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;&lt;em&gt;scraping municipalities of switzerland&lt;/em&gt;
I did Austria which was already pretty hard but Switzerland added a lot of MORE shit that was hard&lt;/p&gt;
&lt;p&gt;&lt;em&gt;scraping snapchat&lt;/em&gt;
I don&amp;rsquo;t have the facilities for that &amp;amp; permutations are important&lt;/p&gt;
&lt;p&gt;&lt;em&gt;scraping oeamtc&lt;/em&gt;
Again: calculate permutations for trying!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>quick analysis of my fellow applicants</title>
      <link>https://bresu.github.io/en/posts/2021-07-28-tu_scraper/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bresu.github.io/en/posts/2021-07-28-tu_scraper/</guid>
      <description>&lt;h1 id=&#34;quick-analysis-of-my-fellow-applicants&#34;&gt;quick analysis of my fellow applicants
&lt;span&gt;&lt;a href=&#34;#quick-analysis-of-my-fellow-applicants&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;created: 20.08.2021&lt;/p&gt;
&lt;h1 id=&#34;context&#34;&gt;context
&lt;span&gt;&lt;a href=&#34;#context&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;So I am (hopefully) gonna be a Computer Science student at the Technical University of Vienna. Yesterday I did the entry exam and I will find out in a week or so if I am accepted or not. Weeks before the exam all applicants got an e-mail invitation to the &amp;ldquo;moodle&amp;rdquo; or &amp;ldquo;edu&amp;rdquo; platform, which is basically just the website where you submit your work and find learning resources.
&lt;strong&gt;The site also had an interesting feature which might be privacy-law violating (maybe!)&lt;/strong&gt;
In the navigation bar of the website there was a &amp;ldquo;participants&amp;rdquo;-tab. I clicked on it and to my surprise:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;You could look up fellow applicants by their first and last name!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It also offered the option to show &lt;strong&gt;all (1000)&lt;/strong&gt; entries on a single page. Obviously I enabled that and wrote the simplest script to just download it and extract all names.
Now I had a table to work with but the question was: what information can I squeeze out of only just the names?
I quickly realized that first names are a VERY strong indicator of gender. (I know that this a very binary look at it, but the probability of non-binary people being present in this list of about 1000 people is negligible and all my results are just stupid estimations)
So I did some research and it turns out that somebody had made a &lt;a href=&#34;https://pypi.org/project/gender-guesser/&#34;&gt;gender-guesser&lt;/a&gt;{:target=&amp;quot;&lt;em&gt;blank&lt;/em&gt;&amp;quot;} python module that uses data from the American Census and other sources to identify gender by name.
&lt;em&gt;Pretty neat - Let&amp;rsquo;s get to work&lt;/em&gt;
I let the program run over my data and these are the results (estimations!):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    male: 662
    female: 200
    unknown: 104
    mostly male: 8
    mostly female: 3
    unisex: 2
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;interesting&#34;&gt;interesting
&lt;span&gt;&lt;a href=&#34;#interesting&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;So we see that gender-equality still has a long way to go&amp;hellip;
You might ask what &amp;ldquo;unknown&amp;rdquo; means. I checked some datapoints and it seems that the data model is very western-centered. So &amp;ldquo;exotic&amp;rdquo; (I hate this term) names are not registered in the model. But one can assume that the distribution of gender in the &amp;ldquo;unknown&amp;rdquo; category is also roughly 3:2.&lt;/p&gt;
&lt;h1 id=&#34;weird-things-i-found&#34;&gt;weird things i found
&lt;span&gt;&lt;a href=&#34;#weird-things-i-found&#34;&gt;#&lt;/a&gt;&lt;/span&gt;
&lt;/h1&gt;&lt;p&gt;So it turns out that some sick fucks (mostly American researchers) also made a &lt;strong&gt;race-guesser&lt;/strong&gt; which in my opinion is super problematic. As I said before about the gender-guesser: this is just an estimation and it excludes non-binary people or other members of the LGBTQIA+ community. But guessing race????
There are so many factors that need to be taken into account. Just because someone&amp;rsquo;s name is Jack Smith doesn&amp;rsquo;t mean he&amp;rsquo;s white. Name changes happen all the time due to marriages etc. so I really have problems regarding the accuracy of modules like this.&lt;/p&gt;
&lt;p&gt;[ WILL UPDATE AT BEGINNING OF NEW SEMESTER ]&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
